name: Unity Integration Tests with Backend

on:
  pull_request:
    branches: [main, dev]

jobs:
  unity-tests:
    name: Unity Tests with Backend Integration
    runs-on: self-hosted
    timeout-minutes: 20

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "18"
          cache: "npm"
          cache-dependency-path: Backend/API/package.json

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install jq for JSON parsing
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Call External Unity Test Service
        id: external-unity-test
        run: |
          # Prepare payload with GitHub context
          PAYLOAD=$(cat <<EOF
          {
            "repository": "${{ github.repository }}",
            "branch": "${{ github.ref_name }}",
            "commit_sha": "${{ github.event.pull_request.head.sha || github.sha }}",
            "commit_message": $(echo '${{ github.event.head_commit.message }}' | jq -Rs . || echo '""'),
            "event_name": "${{ github.event_name }}",
            "pull_request": {
              "number": "${{ github.event.pull_request.number || '' }}",
              "title": $(echo '${{ github.event.pull_request.title || '' }}' | jq -Rs . || echo '""'),
              "base_branch": "${{ github.event.pull_request.base.ref || '' }}",
              "head_branch": "${{ github.event.pull_request.head.ref || '' }}",
              "url": "${{ github.event.pull_request.html_url || '' }}"
            },
            "actor": "${{ github.actor }}",
            "run_id": "${{ github.run_id }}",
            "run_number": "${{ github.run_number }}",
            "workflow": "${{ github.workflow }}"
          }
          EOF
          )

          echo "Sending test request to external Unity test service..."
          echo "Payload: $PAYLOAD"

          # Get response body separately from status code for clearer parsing
          RESPONSE_BODY=$(curl -s -X POST \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer ${{ secrets.UNITY_TEST_SERVICE_TOKEN || 'default-token' }}" \
            -d "$PAYLOAD" \
            "${{ secrets.UNITY_TEST_SERVICE_URL || 'http://localhost:5001' }}/api/run-tests")

          # Get status code separately
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" -X POST \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer ${{ secrets.UNITY_TEST_SERVICE_TOKEN || 'default-token' }}" \
            -d "$PAYLOAD" \
            "${{ secrets.UNITY_TEST_SERVICE_URL || 'http://localhost:5001' }}/api/run-tests")

          echo "HTTP Response Code: $HTTP_CODE"
          echo "Response Body: $RESPONSE_BODY"

          echo "response=$RESPONSE_BODY" >> $GITHUB_OUTPUT
          echo "http_code=$HTTP_CODE" >> $GITHUB_OUTPUT

          if [ "$HTTP_CODE" != "200" ]; then
            echo "::error::Failed to trigger external Unity tests (HTTP $HTTP_CODE): $RESPONSE_BODY"
            exit 1
          fi

          TEST_ID=$(echo "$RESPONSE_BODY" | jq -r '.testId')
          if [ -z "$TEST_ID" ] || [ "$TEST_ID" = "null" ]; then
            echo "::error::No test ID returned from service"
            exit 1
          fi

          echo "test_id=$TEST_ID" >> $GITHUB_OUTPUT
          echo "✅ External Unity test started with ID: $TEST_ID"

      - name: Wait for Test Completion
        run: |
          TEST_ID=${{ steps.external-unity-test.outputs.test_id }}
          SERVICE_URL="${{ secrets.UNITY_TEST_SERVICE_URL || 'http://localhost:5001' }}"
          MAX_ATTEMPTS=60  # 10 minutes with 10s intervals
          ATTEMPT=0

          echo "🔄 Polling test results for ID: $TEST_ID"
          echo "Service URL: $SERVICE_URL"

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            sleep 10  # Wait 10 seconds between checks
            ATTEMPT=$((ATTEMPT + 1))
            
            echo "📡 Checking test status (attempt $ATTEMPT/$MAX_ATTEMPTS)..."
            
            RESPONSE=$(curl -s \
              -H "Authorization: Bearer ${{ secrets.UNITY_TEST_SERVICE_TOKEN || 'default-token' }}" \
              "$SERVICE_URL/api/test-status/$TEST_ID")
            
            if [ $? -ne 0 ]; then
              echo "⚠️  Failed to connect to test service"
              continue
            fi
            
            echo "Response: $RESPONSE"
            STATUS=$(echo "$RESPONSE" | jq -r '.status // "unknown"')
            
            case "$STATUS" in
              "completed")
                SUCCESS=$(echo "$RESPONSE" | jq -r '.success // false')
                TOTAL_TESTS=$(echo "$RESPONSE" | jq -r '.totalTests // 0')
                FAILED_TESTS=$(echo "$RESPONSE" | jq -r '.failedTests // 0')
                PASSED_TESTS=$(echo "$RESPONSE" | jq -r '.passedTests // 0')
                
                # Extract coverage data
                COVERAGE_AVAILABLE=$(echo "$RESPONSE" | jq -r '.coverage.available // false')
                LINE_COVERAGE=$(echo "$RESPONSE" | jq -r '.coverage.lineCoverage // 0')
                METHOD_COVERAGE=$(echo "$RESPONSE" | jq -r '.coverage.methodCoverage // 0')
                TEST_CLASS_COUNT=$(echo "$RESPONSE" | jq -r '.coverage.testClassCount // 0')
                
                echo ""
                echo "🎯 Unity Tests Completed!"
                echo "📊 Results Summary:"
                echo "   • Total Tests: $TOTAL_TESTS"
                echo "   • Passed: $PASSED_TESTS"
                echo "   • Failed: $FAILED_TESTS"
                
                if [ "$COVERAGE_AVAILABLE" = "true" ]; then
                  echo "📈 Coverage Summary:"
                  echo "   • Line Coverage: $LINE_COVERAGE%"
                  echo "   • Method Coverage: $METHOD_COVERAGE%"
                  echo "   • Test Classes: $TEST_CLASS_COUNT"
                  
                  # Set environment variables for later steps
                  echo "coverage_available=true" >> $GITHUB_ENV
                  echo "line_coverage=$LINE_COVERAGE" >> $GITHUB_ENV
                  echo "method_coverage=$METHOD_COVERAGE" >> $GITHUB_ENV
                  echo "test_class_count=$TEST_CLASS_COUNT" >> $GITHUB_ENV
                else
                  echo "ℹ️  No coverage data available"
                  echo "coverage_available=false" >> $GITHUB_ENV
                  echo "line_coverage=0" >> $GITHUB_ENV
                  echo "method_coverage=0" >> $GITHUB_ENV
                  echo "test_class_count=0" >> $GITHUB_ENV
                fi
                echo ""
                
                # Get detailed logs
                echo "📋 Test Logs:"
                LOGS_RESPONSE=$(curl -s \
                  -H "Authorization: Bearer ${{ secrets.UNITY_TEST_SERVICE_TOKEN || 'default-token' }}" \
                  "$SERVICE_URL/api/logs/$TEST_ID")
                
                LOGS=$(echo "$LOGS_RESPONSE" | jq -r '.logs[]? // empty')
                if [ -n "$LOGS" ]; then
                  echo "$LOGS"
                fi
                
                if [ "$SUCCESS" = "true" ] && [ "$FAILED_TESTS" = "0" ] && [ "$TOTAL_TESTS" != "0" ]; then
                  echo "✅ All Unity tests passed!"
                  exit 0
                else
                  echo "❌ Unity tests failed!"
                  echo "::error::Unity tests failed ($FAILED_TESTS/$TOTAL_TESTS failed)"
                  exit 1
                fi
                ;;
              "failed"|"error")
                ERROR_MSG=$(echo "$RESPONSE" | jq -r '.error // "Unknown error"')
                echo "❌ Test execution failed: $ERROR_MSG"
                echo "::error::Unity test execution failed: $ERROR_MSG"
                exit 1
                ;;
              "timeout")
                echo "⏰ Tests timed out on the external service"
                echo "::error::Unity tests timed out"
                exit 1
                ;;
              "running")
                echo "🔄 Tests still running..."
                ;;
              "queued")
                echo "⏳ Tests queued, waiting to start..."
                ;;
              *)
                echo "❓ Unknown status: $STATUS"
                ;;
            esac
          done

          echo "⏰ Test polling timed out after $((MAX_ATTEMPTS * 10)) seconds!"
          echo "::error::Test polling timeout - Unity tests may still be running"
          exit 1

      - name: Generate Coverage Badge
        if: env.coverage_available == 'true'
        run: |
          COVERAGE="${{ env.line_coverage }}"
          echo "🎨 Generating coverage badge with $COVERAGE% coverage"
          python scripts/generate-badge.py "$COVERAGE" docs/images/coverage-badge.svg

      - name: Commit Coverage Badge
        if: env.coverage_available == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Check if badge file changed
          if git diff --quiet docs/images/coverage-badge.svg 2>/dev/null; then
            echo "Coverage badge unchanged, skipping commit"
          else
            git add docs/images/coverage-badge.svg
            git commit -m "Update coverage badge: ${{ env.line_coverage }}% [skip ci]"
            git push
            echo "✅ Coverage badge updated and committed"
          fi

      - name: Create Coverage Check
        if: env.coverage_available == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const coverage = '${{ env.line_coverage }}';
            const methodCoverage = '${{ env.method_coverage }}';
            const testCount = '${{ env.test_class_count }}';
            
            const summary = `Unity Test Coverage: ${coverage}%`;
            
            const output = {
              title: 'Unity Test Coverage Report',
              summary: summary,
              text: `## 🧪 Unity Test Coverage\n\n` +
                    `- **Line Coverage:** ${coverage}%\n` +
                    `- **Method Coverage:** ${methodCoverage}%\n` +
                    `- **Test Classes:** ${testCount}\n\n` +
                    `Coverage includes EditMode tests and selected MainAssembly classes.`
            };
            
            await github.rest.checks.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: 'Unity Test Coverage',
              head_sha: context.sha,
              status: 'completed',
              conclusion: 'neutral',
              output: output
            });

      - name: Calculate and Report Coverage
        if: always()
        run: |
          # Run our coverage calculation locally if coverage files exist
          if [ -f "Unity/CodeCoverage/Report/Summary.json" ]; then
            echo "📊 Calculating coverage for selected test classes..."
            python scripts/calculate-coverage.py --github
            
            # Also generate JSON for artifacts
            python scripts/calculate-coverage.py --json > coverage-summary.json
            
            echo "✅ Coverage calculation completed"
          else
            echo "ℹ️  No local coverage data found"
          fi

      - name: Upload Coverage Summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unity-coverage-summary-${{ github.run_number }}
          path: |
            coverage-summary.json
            Unity/CodeCoverage/Report/Summary.json
          retention-days: 30
          if-no-files-found: warn

      - name: Comment Coverage on PR
        if: github.event_name == 'pull_request' && hashFiles('coverage-summary.json') != ''
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            try {
              const coverage = JSON.parse(fs.readFileSync('coverage-summary.json', 'utf8'));
              
              if (coverage.editmode_tests_found) {
                const linePercent = coverage.overall_line_coverage;
                const methodPercent = coverage.overall_method_coverage;
                const quality = linePercent >= 90 ? '🟢 Excellent' : 
                               linePercent >= 70 ? '🟡 Good' : '🔴 Needs Improvement';
                
                let comment = `## 🧪 Unity Test Coverage Report
            
            | Metric | Coverage | Status |
            |--------|----------|---------|
            | 📊 Overall Quality | ${quality} | |
            | 📝 Line Coverage | ${linePercent}% (${coverage.total_covered_lines}/${coverage.total_coverable_lines}) | ${linePercent >= 70 ? '✅' : '❌'} |
            | 🔧 Method Coverage | ${methodPercent}% (${coverage.total_covered_methods}/${coverage.total_methods}) | ${methodPercent >= 70 ? '✅' : '❌'} |
            | 🎯 Test Classes | ${coverage.test_count} | |
            
            ### 📋 Coverage by Assembly
            `;
                
                if (coverage.by_assembly) {
                  if (coverage.by_assembly.EditMode && coverage.by_assembly.EditMode.length > 0) {
                    comment += `\n**EditMode Tests (${coverage.by_assembly.EditMode.length}):**\n`;
                    coverage.by_assembly.EditMode.forEach(test => {
                      const status = test.line_coverage >= 90 ? '🟢' : test.line_coverage >= 70 ? '🟡' : '🔴';
                      comment += `- ${status} ${test.name}: ${test.line_coverage}%\n`;
                    });
                  }
                  
                  if (coverage.by_assembly.MainAssembly && coverage.by_assembly.MainAssembly.length > 0) {
                    comment += `\n**MainAssembly Classes (${coverage.by_assembly.MainAssembly.length}):**\n`;
                    coverage.by_assembly.MainAssembly.forEach(test => {
                      const status = test.line_coverage >= 90 ? '🟢' : test.line_coverage >= 70 ? '🟡' : '🔴';
                      comment += `- ${status} ${test.name}: ${test.line_coverage}%\n`;
                    });
                  }
                }
                
                const summary = coverage.summary;
                comment += `\n### � Summary
            - 🟢 Excellent (≥90%): ${summary.excellent} classes
            - 🟡 Good (70-89%): ${summary.good} classes  
            - 🔴 Needs work (<70%): ${summary.needs_improvement} classes
            
            ---
            *Coverage calculated from selected EditMode tests and MainAssembly classes*`;
                
                await github.rest.issues.createComment({
                  issue_number: context.issue.number,
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  body: comment
                });
              }
            } catch (error) {
              console.log('Could not post coverage comment:', error);
            };
